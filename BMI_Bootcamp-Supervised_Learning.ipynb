{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI ML Bootcamp #1 - Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graphviz import Source\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first tutorial, we'll be working with the standard scikit-learn iris dataset. This contains sepal length, sepal width, petal length and petal width for three iris types (Setosa, Versicolour, and Virginica). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(data = np.c_[iris['data'], iris['target']], columns = iris['feature_names'] + ['target'])\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick 3 data fields and create a 3D scatterplot with the points colored by target.\n",
    "\n",
    "Did the classes separate out visually when plotted by the three fields you chose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split iris data up into test/training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# What size test set is reasonable?\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = ?) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest Classifier \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Random Forest Classifier\n",
    "Some hyperparameters to test:\n",
    "* n_estimators\n",
    "* criterion\n",
    "* max_depth\n",
    "* max_features\n",
    "and lots of others - see documentation for all the options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RandomForestClassifier and fit using your training data\n",
    "rfc = RandomForestClassifier() \n",
    "rfc.fit(?, ?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well does your model perform on your test set?\n",
    "\n",
    "rfc.score(?, ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few of your trees using the code below. How do they differ from one another? Does changing the number of estimators or the leaf criteria significantly affect the look of individual trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = rfc.estimators_[?]\n",
    "graph = Source(export_graphviz(tree, out_file=None, feature_names=iris.feature_names, class_names = iris.target_names))\n",
    "SVG(graph.pipe(format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the top important features? (hint - look at the RandomForestClassifier attributes)\n",
    "What feature was the most important? Does this change as you modify the hyperparameters of your model? If you train without that feature, what accuracy do you achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. k Nearest Neighbors\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create KNeighbor classifier and train on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = ?\n",
    "neigh.fit(?, ?)\n",
    "neigh.score(?, ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code below, plot the decision boundaries. Do they look reasonable? How do they change if you change k? How do they change if you use uniform weights vs. distance weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundaries(model, training_X, training_y, n_neighbors):\n",
    "\n",
    "    X = training_X[:, :2]\n",
    "    y = training_y\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    h = .02 \n",
    "\n",
    "    cmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\n",
    "    cmap_bold = ListedColormap(['darkorange', 'c', 'darkblue'])\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = data[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "                edgecolor='k', s=20)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"3-Class classification (k = %i)\" % (n_neighbors))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_boundaries(KNeighborsClassifier(n_neighbors=?), X_train, y_train, ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does this model perform on your test set? What value of k results in the highest accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Support Vector Machines\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train a support vector classifier, then test its accuracy on your training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What points does your model consider to be the support vectors? Plot them on the 3d graph you made above - do they seem reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a few different kernels. Do they improve performance? Which worked the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Of the three classifiers, which classifier performed the best? Is it the one that you expected? Which performed the worst?\n",
    "\n",
    "If you're curious, scikit-learn implements a bunch of other classifiers, such as AdaBoost and Naive bayes that you could try. Alternatively, you could use one of the features as a label instead and treat this as a regression task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ml-tutorial)",
   "language": "python",
   "name": "ml-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
